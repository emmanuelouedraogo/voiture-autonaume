# üöó Voiture Autonome - API de Segmentation d'Image

Ce projet fournit une solution compl√®te et conteneuris√©e pour d√©ployer un mod√®le de segmentation d'images. Il se compose de plusieurs services orchestr√©s par Docker Compose :

1. **Une API RESTful** (service `api`) construite avec **FastAPI** qui prend une image en entr√©e et retourne son masque de segmentation.
2. **Une interface utilisateur web** (service `frontend`) construite avec **Streamlit** qui permet d'interagir facilement avec l'API.

Le projet est structur√© pour √™tre facilement personnalisable et d√©ployable avec Docker.

## ‚ú® Fonctionnalit√©s

- **API Performante** : Utilise FastAPI pour des r√©ponses rapides et asynchrones.
- **Interface Intuitive** : Permet d'uploader une image et de visualiser l'original et le masque de segmentation c√¥te √† c√¥te.
- **Modulaire** : La logique de segmentation est isol√©e, ce qui permet de la remplacer facilement par votre propre mod√®le.
- **Pr√™t pour le D√©ploiement** : Inclut un `Dockerfile` pour conteneuriser l'API et la d√©ployer sur n'importe quel service cloud.

## üìÇ Structure du Projet

```
voiture-autonome/
‚îú‚îÄ‚îÄ .gitignore          # Fichiers √† ignorer par Git
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py         # Code de l'API FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ segmentation.py # Logique de l'algorithme de segmentation
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ app.py          # Code de l'application Streamlit
‚îú‚îÄ‚îÄ app.Dockerfile      # Instructions pour construire l'image Docker de Streamlit
‚îú‚îÄ‚îÄ models/             # Dossier pour stocker les mod√®les entra√Æn√©s (ex: .h5, .pt)
‚îú‚îÄ‚îÄ requirements.txt    # D√©pendances Python
‚îú‚îÄ‚îÄ Dockerfile          # Instructions pour construire l'image Docker de l'API
‚îî‚îÄ‚îÄ README.md           # Ce fichier
`

## üöÄ D√©marrage Rapide (avec Docker)

C'est la m√©thode recommand√©e pour lancer l'ensemble du projet.

### Pr√©requis

- [Docker](https://www.docker.com/get-started)
- [Docker Compose](https://docs.docker.com/compose/install/)

### Lancement pour le d√©veloppement (avec monitoring)

Cette commande lance tous les services, y compris l'API, le frontend et la stack de monitoring (Grafana, Loki). C'est id√©al pour le d√©veloppement et le d√©bogage.

```bash
# Construit les images et lance tous les conteneurs en arri√®re-plan
docker-compose up --build -d
```

Une fois les services d√©marr√©s :

- **L'interface web** est accessible √† l'adresse `http://localhost:8501`.
- **L'API** est accessible √† l'adresse `http://localhost:8000`.
- **Grafana** (pour les logs) est accessible √† `http://localhost:3000`.

## üíª D√©veloppement Local (sans Docker)

Suivez ces √©tapes pour lancer l'API et le frontend directement sur votre machine.

### 1. Pr√©requis

- Python 3.12+

### 2. Installation

```bash
# Cr√©ez un environnement virtuel et activez-le (exemple pour Windows)
python -m venv voitautoenv
.\voitautoenv\Scripts\activate

# Installez les d√©pendances
pip install -r requirements.txt
```

### 3. Lancement

Vous devez lancer l'API et l'interface Streamlit dans **deux terminaux distincts**.

**Terminal 1 : Lancez l'API FastAPI**

```bash
uvicorn api.main:app --reload
```

> L'API sera accessible √† l'adresse `http://127.0.0.1:8000`.

**Terminal 2 : Lancez l'interface Streamlit**

```bash
streamlit run app/app.py
```

> L'interface web sera accessible √† l'adresse `http://localhost:8501`.

## üîß Personnalisation

Pour utiliser votre propre mod√®le de segmentation, la m√©thode recommand√©e est de configurer les variables d'environnement via Docker Compose.
Pour utiliser votre propre mod√®le de segmentation, il suffit de modifier les variables d'environnement dans le fichier `docker-compose.yml`.

1. Placez votre fichier de mod√®le (ex: `best_model_final.keras`) dans le dossier `models/`.
2. Assurez-vous d'avoir un fichier de mapping de classes (ex: `class_mapping.json`) dans le dossier `models/`. Ce fichier doit mapper les index de classe (en tant que cha√Ænes de caract√®res) √† des couleurs RGB.
   Voici un exemple de format valide pour `class_mapping.json`:
1. Ouvrez le fichier `docker-compose.yml`.
2. Localisez la section `environment` du service `api`.
3. Modifiez les URLs pour pointer vers vos propres fichiers de mod√®le et de mapping.

   ```json
   {
     "0": [128, 64, 128],
     "1": [244, 35, 232],
     "2": [70, 70, 70]
   }
   ```

3. Ouvrez le fichier `docker-compose.yml` et modifiez les variables d'environnement du service `api` pour qu'elles correspondent √† vos noms de fichiers.

   ```yaml
   environment:
      - MODEL_FILENAME=best_model_final.keras
      - CLASS_MAPPING_FILENAME=class_mapping.json
      - MODEL_URL=<URL_VERS_VOTRE_MODELE.keras>
      - CLASS_MAPPING_URL=<URL_VERS_VOTRE_MAPPING.json>
   ```

4. Relancez l'application avec `docker-compose up --build`.
4. Relancez l'application avec `docker-compose up --build`. Les fichiers seront automatiquement t√©l√©charg√©s au premier d√©marrage.

## üåê D√©ploiement

Ce projet est configur√© pour un d√©ploiement continu sur **Hugging Face Spaces**, une plateforme gratuite et bien adapt√©e aux applications de Machine Learning.

### Pr√©requis

- Un compte Docker Hub o√π les images sont pouss√©es par le workflow CI.
- Un compte Hugging Face.

### √âtapes de d√©ploiement sur Hugging Face

1. **Cr√©ez un nouveau "Space"** sur Hugging Face.
2. Choisissez **"Docker"** comme SDK et "Public" comme visibilit√©.
3. Une fois le Space cr√©√©, allez dans l'onglet **"Settings"**.
4. Dans la section "Docker template", cochez **"Use a Docker image from the Hub"**.
5. Entrez le nom de l'image de l'API : `emmanuelouedraogo/voiture-autonome-api:latest`.
6. Assurez-vous que le "Application port" est bien `8000`.
7. Ajoutez les secrets n√©cessaires (ex: `INTERNAL_API_KEY`) dans la section "Repository secrets".
8. Sauvegardez les changements.

Hugging Face d√©ploiera automatiquement votre conteneur. L'URL publique de votre API sera disponible sur la page principale de votre Space.

> **Note** : Le frontend Streamlit peut √©galement √™tre d√©ploy√© de la m√™me mani√®re en cr√©ant un second Space et en utilisant l'image `emmanuelouedraogo/voiture-autonome-frontend:latest`. N'oubliez pas de configurer la variable d'environnement `API_URL` dans les secrets du Space frontend pour qu'elle pointe vers l'URL de votre API d√©ploy√©e.
